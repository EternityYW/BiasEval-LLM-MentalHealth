{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accdd557-fd0f-4bcc-9a79-e38e63938d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f2834-5420-45e5-aaae-e3670475ab73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint = \" \",\n",
    "    api_key=\"<your_api_key>\",\n",
    "    api_version=\" \"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5eaf6-514c-40fa-8c69-21ed62163e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Divide yoru dataframe into chucks if it is large\n",
    "'''\n",
    "num_chunks = 10\n",
    "chunk_size = len(df) // num_chunks\n",
    "\n",
    "# Split the DataFrame into 10 chunks\n",
    "chunks = [df[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "# Assign each chunk to a separate variable df1 to df10\n",
    "df1, df2, df3, df4, df5, df6, df7, df8, df9, df10 = chunks\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da748f26-0a27-42fa-b73c-57b6427979a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMS (can be adapted to binary and multi-class classification datasets)\n",
    "df = pd.read_csv(\"CAMS_var.csv\")\n",
    "system_prompt = \"You are a mental health specialist. Analyze the provided text for signs of mental health issues like depression, anxiety, or other mental disorders. Take social factors such as race, gender, age, sexuality, nationality, and religion into account. Provide a brief explanation of your prediction considering both social factors and the text given.\"\n",
    "predictions = []\n",
    "reasonings = []\n",
    "bad_sample = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    user_prompt = f\"Given the post: '{row['text']}', analyze the content to identify the most possible cause of the user's mental issue. The output should be in the form of 'OUTPUT: 0 (No reason)' or 'OUTPUT: 1 (Bias or abuse)' or 'OUTPUT: 2 (Jobs and Careers)' or 'OUTPUT: 3 (Medication)' or 'OUTPUT: 4 (Relationship)' or 'OUTPUT: 5 (Alienation)'; REASONING:\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ])\n",
    "        content = response.choices[0].message.content      \n",
    "        time.sleep(0.1)\n",
    "        prediction_match = re.search(r'OUTPUT: (\\d+)', content)\n",
    "        reasoning_match = re.search(r'REASONING: (.*)', content)\n",
    "        prediction = prediction_match.group(1) if prediction_match else None\n",
    "        reasoning = reasoning_match.group(1) if reasoning_match else None\n",
    "        if i % 50 == 0:\n",
    "            print('Progress:', i, 'finished')\n",
    "    except Exception as e:\n",
    "        prediction = None\n",
    "        reasoning = None\n",
    "        bad_sample.append((i, str(e)))\n",
    "        print('Error:', i, str(e)[:8])\n",
    "    predictions.append(prediction)\n",
    "    reasonings.append(reasoning)\n",
    "\n",
    "\n",
    "df['prediction'] = predictions\n",
    "df['reasoning'] = reasonings\n",
    "df.to_csv(\"CAMS_var_GPT4.csv\", index=False)\n",
    "csv_file = \"CAMS_var_GPT4_bad_sample_index.csv\"\n",
    "\n",
    "# Writing the list of tuples to a CSV file\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Writing the header (if necessary)\n",
    "    writer.writerow([\"Row_num\", \"Error_msg\"])\n",
    "    \n",
    "    # Writing the data\n",
    "    writer.writerows(bad_sample)\n",
    "\n",
    "print(f\"Data saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52233102-e078-4818-af60-5a000e8587f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IRF\n",
    "'''\n",
    "df = pd.read_csv(\"IRF_var.csv\")\n",
    "system_prompt = \"You are a mental health specialist. Analyze the provided text for signs of mental health issues like depression, anxiety, or other mental disorders. Take social factors such as race, gender, age, sexuality, nationality, and religion into account. Provide a brief explanation of your prediction considering both social factors and the text given.\"\n",
    "tb_predictions = []\n",
    "tb_reasonings = []\n",
    "pb_predictions = []\n",
    "pb_reasonings = []\n",
    "bad_sample = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    user_prompt = f\"Given the post: '{row['text']}', analyze the content to identify the presence of Thwarted Belongingness and Perceived Burdensomeness. The output should be in the following format:\\n\\n'Thwarted Belongingness: OUTPUT: 0 (No) or 1 (Yes); REASONING:'\\n\\n'Perceived Burdensomeness: OUTPUT: 0 (No) or 1 (Yes); REASONING:\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ])\n",
    "        content = response.choices[0].message.content      \n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        # Extract Thwarted Belongingness\n",
    "        tb_prediction_match = re.search(r'Thwarted Belongingness: OUTPUT: (\\d+)', content)\n",
    "        tb_reasoning_match = re.search(r'Thwarted Belongingness.*?REASONING: (.*?)(?=Perceived Burdensomeness|$)', content, re.DOTALL)\n",
    "        tb_prediction = tb_prediction_match.group(1) if tb_prediction_match else None\n",
    "        tb_reasoning = tb_reasoning_match.group(1).strip() if tb_reasoning_match else None\n",
    "        \n",
    "        # Extract Perceived Burdensomeness\n",
    "        pb_prediction_match = re.search(r'Perceived Burdensomeness: OUTPUT: (\\d+)', content)\n",
    "        pb_reasoning_match = re.search(r'Perceived Burdensomeness.*?REASONING: (.*?)(?=Thwarted Belongingness|$)', content, re.DOTALL)\n",
    "        pb_prediction = pb_prediction_match.group(1) if pb_prediction_match else None\n",
    "        pb_reasoning = pb_reasoning_match.group(1).strip() if pb_reasoning_match else None\n",
    "        if i % 50 == 0:\n",
    "            print('Progress:', i, 'finished')\n",
    "    except Exception as e:\n",
    "        tb_prediction = None\n",
    "        tb_reasoning = None\n",
    "        pb_prediction = None\n",
    "        pb_reasoning = None\n",
    "        bad_sample.append((i, str(e)))\n",
    "        print('Error:', i, str(e)[:8])\n",
    "    tb_predictions.append(tb_prediction)\n",
    "    tb_reasonings.append(tb_reasoning)\n",
    "    pb_predictions.append(pb_prediction)\n",
    "    pb_reasonings.append(pb_reasoning)\n",
    "\n",
    "df['TBe_prediction'] = tb_predictions\n",
    "df['Tbe_reasoning'] = tb_reasonings\n",
    "df['PBu_prediction'] = pb_predictions\n",
    "df['PBu_reasoning'] = pb_reasonings\n",
    "\n",
    "df.to_csv(\"IRF_var_GPT4.csv\", index=False)\n",
    "csv_file = \"IRF_var_GPT4_bad_sample_index.csv\"\n",
    "\n",
    "# Writing the list of tuples to a CSV file\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Writing the header (if necessary)\n",
    "    writer.writerow([\"Row_num\", \"Error_msg\"])\n",
    "    \n",
    "    # Writing the data\n",
    "    writer.writerows(bad_sample)\n",
    "\n",
    "print(f\"Data saved to {csv_file}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a3374-6bf5-43f1-aa6f-f7ec9fc83694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MultiWD\n",
    "'''\n",
    "df = pd.read_csv(\"MultiWD_var.csv\")\n",
    "system_prompt = \"You are a mental health specialist. Analyze the provided text for signs of mental health issues like depression, anxiety, or other mental disorders. Take social factors such as race, gender, age, sexuality, nationality, and religion into account. Provide a brief explanation of your prediction considering both social factors and the text given.\"\n",
    "\n",
    "bad_sample = []\n",
    "\n",
    "# Initialize predictions and reasonings dictionaries outside the loop\n",
    "dimensions = [\"Spiritual\", \"Physical\", \"Intellectual\", \"Social\", \"Vocational\", \"Emotional\"]\n",
    "predictions = {dimension: [] for dimension in dimensions}\n",
    "reasonings = {dimension: [] for dimension in dimensions}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    user_prompt = f\"Given the post: '{row['text']}', analyze the content to identify relevant wellness dimensions. The output should be in the following format:\\n\\n'Spiritual: OUTPUT: 0 (No) or 1 (Yes); REASONING:'\\n\\n'Physical: OUTPUT: 0 (No) or 1 (Yes); REASONING:\\n\\n'Intellectual: OUTPUT: 0 (No) or 1 (Yes); REASONING:'\\n\\n'Social: OUTPUT: 0 (No) or 1 (Yes); REASONING:\\n\\n'Vocational: OUTPUT: 0 (No) or 1 (Yes); REASONING:'\\n\\n'Emotional: OUTPUT: 0 (No) or 1 (Yes); REASONING:'\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        for dimension in dimensions:\n",
    "            # Use regex to find the dimension with or without space\n",
    "            dim_match = re.search(f\"{dimension}: ?OUTPUT:\", content)\n",
    "            if dim_match:\n",
    "                dim_start = dim_match.start()\n",
    "                dim_segment = content[dim_start:].split(\"\\n\", 1)[0].strip()\n",
    "                if \"OUTPUT: 1\" in dim_segment:\n",
    "                    predictions[dimension].append(1)\n",
    "                elif \"OUTPUT: 0\" in dim_segment:\n",
    "                    predictions[dimension].append(0)\n",
    "                else:\n",
    "                    predictions[dimension].append(None)\n",
    "\n",
    "                reasoning_start = dim_segment.find(\"REASONING:\")\n",
    "                if reasoning_start != -1:\n",
    "                    reasoning = dim_segment[reasoning_start + len(\"REASONING:\"):].strip()\n",
    "                else:\n",
    "                    reasoning = \"\"\n",
    "\n",
    "                reasonings[dimension].append(reasoning)\n",
    "            else:\n",
    "                predictions[dimension].append(None)\n",
    "                reasonings[dimension].append(\"\")\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print('Progress:', i, 'finished')\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Set current predictions and reasonings to None\n",
    "        for dimension in dimensions:\n",
    "            predictions[dimension].append(None)\n",
    "            reasonings[dimension].append(None)\n",
    "        bad_sample.append((i, str(e)))\n",
    "        print('Error:', i, str(e)[:8])\n",
    "\n",
    "# Assign predictions and reasonings to dataframe columns\n",
    "for dimension in dimensions:\n",
    "    df[f'{dimension}_prediction'] = predictions[dimension]\n",
    "    df[f'{dimension}_reasoning'] = reasonings[dimension]\n",
    "\n",
    "df.to_csv(\"MultiWD_var_GPT4.csv\", index=False)\n",
    "csv_file = \"MultiWD_var_GPT4_bad_sample_index.csv\"\n",
    "\n",
    "# Writing the list of tuples to a CSV file\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Writing the header (if necessary)\n",
    "    writer.writerow([\"Row_num\", \"Error_msg\"])\n",
    "    \n",
    "    # Writing the data\n",
    "    writer.writerows(bad_sample)\n",
    "\n",
    "print(f\"Data saved to {csv_file}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c91bc0c-35a6-4ace-8d4a-9ff5ca38bbe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SAD\n",
    "'''\n",
    "df = pd.read_csv(\"SAD.csv\")\n",
    "system_prompt = \"You are a mental health specialist. Analyze the provided text for signs of mental health issues like depression, anxiety, or other mental disorders. Take social factors such as race, gender, age, sexuality, nationality, and religion into account. Provide a brief explanation of your prediction considering both social factors and the text given.\"\n",
    "\n",
    "bad_sample = []\n",
    "\n",
    "dimensions = [\"Financial_Problem\", \"Everyday_Decision_Making\", \"Emotional_Turmoil\", \"School\", \"Family_Issues\", \"Social_Relationships\", \"Work\", \"Health_Fatigue_Physical_Pain\", \"Other\"]\n",
    "predictions = {dimension: [] for dimension in dimensions}\n",
    "reasonings = {dimension: [] for dimension in dimensions}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    user_prompt = f\"Given the post: '{row['text']}', analyze the content to identify all relevant stressor categories. Provide predictions for each of the following categories. The output should be in the following format:\\n\\n'Financial_Problem: 0 (No) or 1 (Yes); REASONING:'\\n\\n'Everyday_Decision_Making: 0 (No) or 1 (Yes); REASONING:'\\n\\n'Emotional_Turmoil: 0 (No) or 1 (Yes); REASONING:'\\n\\n'School: 0 (No) or 1 (Yes); REASONING:'\\n\\n'Family Issues: 0 (No) or 1 (Yes); REASONING:'\\n\\n'Social_Relationships: 0 (No) or 1 (Yes); REASONING:'\\n\\n'Work: 0 (No) or 1 (Yes); REASONING:'\\n\\n'Health_Fatigue_Physical_Pain: 0 (No) or 1 (Yes); REASONING:'\\n\\n'Other: 0 (No) or 1 (Yes); REASONING:'\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        for dimension in dimensions:\n",
    "            dim_match = re.search(f\"{dimension}: (\\d) \\(\\w+\\); REASONING: (.*?)(?=(?:'{dimensions[-1]}:|$))\", content, re.DOTALL)\n",
    "            if dim_match:\n",
    "                output = int(dim_match.group(1))\n",
    "                reasoning = dim_match.group(2).strip()\n",
    "                predictions[dimension].append(output)\n",
    "                reasonings[dimension].append(reasoning)\n",
    "            else:\n",
    "                predictions[dimension].append(None)\n",
    "                reasonings[dimension].append(\"\")\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print('Progress:', i, 'finished')\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Set current predictions and reasonings to None\n",
    "        for dimension in dimensions:\n",
    "            predictions[dimension].append(None)\n",
    "            reasonings[dimension].append(None)\n",
    "        bad_sample.append((i, str(e)))\n",
    "        print('Error:', i, str(e)[:8])\n",
    "\n",
    "# Assign predictions and reasonings to dataframe columns\n",
    "for dimension in dimensions:\n",
    "    df[f'{dimension}_prediction'] = predictions[dimension]\n",
    "    df[f'{dimension}_reasoning'] = reasonings[dimension]\n",
    "\n",
    "df.to_csv(\"SAD_var_GPT4.csv\", index=False)\n",
    "csv_file = \"SAD_var_GPT4_bad_sample_index.csv\"\n",
    "\n",
    "# Writing the list of tuples to a CSV file\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Writing the header (if necessary)\n",
    "    writer.writerow([\"Row_num\", \"Error_msg\"])\n",
    "    \n",
    "    # Writing the data\n",
    "    writer.writerows(bad_sample)\n",
    "\n",
    "print(f\"Data saved to {csv_file}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74fba1-abb8-4184-8302-53cfd9d99dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
